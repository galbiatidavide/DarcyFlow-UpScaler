{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-american",
   "metadata": {},
   "source": [
    "# Optimal well disposition for the Darcy problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-danger",
   "metadata": {},
   "source": [
    "First we import some of the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import porepy as pp\n",
    "import scipy.sparse as sps\n",
    "import scipy\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d2c82",
   "metadata": {},
   "source": [
    "Depending on the setting, we then need to setup the local path for importing some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = \"./\"\n",
    "spe10_folder = main_folder + \"spe10\"\n",
    "sys.path.insert(1, spe10_folder)\n",
    "\n",
    "from functions import *\n",
    "from spe10 import Spe10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ff136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_fine(spe10, pos_well, injection_rate=1, well_pressure=0, export_folder=None):\n",
    "    \"\"\"\n",
    "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
    "    gradient.\n",
    "\n",
    "    Args:\n",
    "        spe10 (object): The object representing the subdomain.\n",
    "        pos_well (np.ndarray): The position of the production well.\n",
    "        injection_rate (float, optional): The injection rate of the wells. Defaults to 1.\n",
    "        well_pressure (float, optional): The pressure at the production well. Defaults to 0.\n",
    "        export_folder (str, optional): If given, path where to export the results. Defaults to\n",
    "            None.\n",
    "\n",
    "    Returns:\n",
    "        float: The maximum pressure at the injection wells.\n",
    "    \"\"\"\n",
    "    # Extract the grid for simplicity\n",
    "    sd = spe10.sd\n",
    "    perm_dict = spe10.perm_as_dict()\n",
    "\n",
    "    # Permeability\n",
    "    perm_tensor = pp.SecondOrderTensor(kxx=perm_dict[\"kxx\"])\n",
    "    print(perm_tensor)\n",
    "\n",
    "    # Boundary conditions\n",
    "    b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
    "\n",
    "    # Define the labels and values for the boundary faces\n",
    "    labels = np.array([\"neu\"] * b_faces.size)\n",
    "    bc_val = np.zeros(sd.num_faces)\n",
    "    bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
    "\n",
    "    # Collect all parameters in a dictionary\n",
    "    key = \"flow\"\n",
    "    parameters = {\"second_order_tensor\": perm_tensor, \"bc\": bc, \"bc_values\": bc_val}\n",
    "    data = pp.initialize_default_data(sd, {}, key, parameters)\n",
    "\n",
    "    # Discretize the problem\n",
    "    discr = pp.Mpfa(key)\n",
    "    discr.discretize(sd, data)\n",
    "\n",
    "    A, b = discr.assemble_matrix_rhs(sd, data)\n",
    "\n",
    "    # Add the injection wells, all with the same injection rate\n",
    "    b_wells = np.zeros_like(b)\n",
    "    index_iwells = [\n",
    "        0,\n",
    "        spe10.full_shape[0] - 1,\n",
    "        spe10.full_shape[0] * spe10.full_shape[1] - spe10.full_shape[0],\n",
    "        spe10.full_shape[0] * spe10.full_shape[1] - 1,\n",
    "    ]\n",
    "    b_wells[index_iwells] = injection_rate\n",
    "\n",
    "    # Add the production well by using a Lagrange multiplier, first we identify the cell\n",
    "    ij_well = np.floor((np.asarray(pos_well) / spe10.spacing[:-1])).astype(int)\n",
    "    print(ij_well)\n",
    "    index_pwell = spe10.full_shape[0] * ij_well[1] + ij_well[0]\n",
    "    vect = np.zeros((sd.num_cells, 1))\n",
    "    vect[index_pwell] = 1\n",
    "\n",
    "    # Solve the linear system and compute the pressure by adding the constraint\n",
    "    A = sps.bmat([[A, vect], [vect.T, None]], format=\"csc\")\n",
    "    b = np.append(b + b_wells, well_pressure)\n",
    "    p = sps.linalg.spsolve(A, b)[:-1]\n",
    "\n",
    "    # extract the discretization matrices build \n",
    "    mat_discr = data[pp.DISCRETIZATION_MATRICES][key]\n",
    "\n",
    "    # reconstruct the flux as post-process\n",
    "    q_tpfa = mat_discr[\"flux\"] @ p + mat_discr[\"bound_flux\"] @ bc_val\n",
    "\n",
    "    # to export the flux                                                                                                   \n",
    "    mvem = pp.MVEM(key)                                                                                      \n",
    "    mvem.discretize(sd, data)                                                                                                                                                                                     \n",
    "    # construct the P0 flux reconstruction                                                                                 \n",
    "    cell_q_mpfa = mvem.project_flux(sd, q_tpfa, data) \n",
    "    \n",
    "\n",
    "    # Export the solution\n",
    "    if export_folder is not None:\n",
    "        save = pp.Exporter(sd, \"sol\", folder_name=export_folder)\n",
    "        save.write_vtu([(\"p\", p), (\"log_kxx\", np.log10(perm_dict[\"kxx\"])),(\"q_mpfa\", cell_q_mpfa)])\n",
    "\n",
    "    # Return the maximum pressure at the injection wells\n",
    "    return np.max(p[index_iwells])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(sd, perm, dir, export_folder=None):\n",
    "    \"\"\"\n",
    "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
    "    gradient.\n",
    "\n",
    "    Args:\n",
    "        sd (pp.Grid): The grid representing the subdomain.\n",
    "        perm (dict): The permeability of the subdomain divided in the fields \"kxx\" and \"kyy\"\n",
    "        dir (int): The direction of the flow, 0 means x-direction and 1 means y-direction.\n",
    "        export_folder (str): If given, path where to export the results.\n",
    "            Default to None, no exporting.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): averaged gradient and flux.\n",
    "    \"\"\"\n",
    "    # TODO: from checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa945bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tensor(grad_h, grad_v, q_h, q_v):\n",
    "    \"\"\"\n",
    "    Compute the upscaled permeability tensor.\n",
    "\n",
    "    Args:\n",
    "        grad_h (np.ndarray): Gradient in the horizontal direction.\n",
    "        grad_v (np.ndarray): Gradient in the vertical direction.\n",
    "        q_h (np.ndarray): Flux in the horizontal direction.\n",
    "        q_v (np.ndarray): Flux in the vertical direction.\n",
    "\n",
    "    Returns:\n",
    "        perm (np.ndarray): Upscaled permeability tensor.\n",
    "\n",
    "    The function solves a linear system to obtain the upscaled permeability tensor\n",
    "    based on the given gradients and fluxes. It enforces numerical symmetry and\n",
    "    checks if the resulting tensor is symmetric positive definite (SPD).\n",
    "    \"\"\"\n",
    "    # Solve the linear system to get the upscaled permeability\n",
    "    \n",
    "    # TODO: from checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = 35\n",
    "folder_results = main_folder + \"results/\"\n",
    "\n",
    "# Read the SPE10 grid\n",
    "spe10 = Spe10(selected_layers)\n",
    "\n",
    "# Read the permeability associated to the given layer(s)\n",
    "perm_folder = spe10_folder + \"/perm/\"\n",
    "spe10.read_perm(perm_folder)\n",
    "perm_dict = spe10.perm_as_dict()\n",
    "\n",
    "# Partition the grid\n",
    "num_part = 10 * 10\n",
    "part, sub_sds, sd_coarse = coarse_grid(spe10.sd, num_part)\n",
    "\n",
    "# Define the upscaled permeability\n",
    "kxx_up = np.zeros(spe10.sd.num_cells)\n",
    "kxy_up = np.zeros(spe10.sd.num_cells)\n",
    "kyx_up = np.zeros(spe10.sd.num_cells)\n",
    "kyy_up = np.zeros(spe10.sd.num_cells)\n",
    "\n",
    "kxx = np.zeros(spe10.sd.num_cells)\n",
    "\n",
    "result = []\n",
    "# Loop over the subdomains\n",
    "for sub_sd_id, sub_sd in enumerate(sub_sds):\n",
    "    # Extract the permeability values associated to the current subdomain\n",
    "    mask = part == sub_sd_id\n",
    "    sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
    "    kxx[mask] = sub_perm[\"kxx\"]\n",
    "\n",
    "    # Upscale the permeability in the x-direction\n",
    "    folder = folder_results + str(sub_sd_id) + \"_x\"\n",
    "    q_h, grad_h = upscale(sub_sd, sub_perm, 0, folder)\n",
    "\n",
    "    # Upscale the permeability in the y-direction\n",
    "    folder = folder_results + str(sub_sd_id) + \"_y\"\n",
    "    q_v, grad_v = upscale(sub_sd, sub_perm, 1, folder)\n",
    "\n",
    "    # Compute the upscaling permeability tensor\n",
    "    kk = compute_tensor(grad_h, grad_v, q_h, q_v)\n",
    "\n",
    "    # Save the data\n",
    "    kxx_up[mask] = kk[0]\n",
    "    kxy_up[mask] = kk[1]\n",
    "    kyx_up[mask] = kk[2]\n",
    "    kyy_up[mask] = kk[3]\n",
    "\n",
    "    result.append([kk[0], kk[1], kk[2], kk[3]])\n",
    "\n",
    "    print(f\"Subdomain {sub_sd_id}: {kk}\")\n",
    "\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-glossary",
   "metadata": {},
   "source": [
    "Define the function that given a subdomain, its data, and a direction compute the upscaled gradient and flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_coarse(\n",
    "    sd,\n",
    "    pos_well,\n",
    "    kk,\n",
    "    injection_rate=1,\n",
    "    well_pressure=0,\n",
    "    export_folder=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
    "    gradient.\n",
    "\n",
    "    Args:\n",
    "        spe10 (object): The object representing the subdomain.\n",
    "        pos_well (np.ndarray): The position of the production well.\n",
    "        injection_rate (float, optional): The injection rate of the wells. Defaults to 1.\n",
    "        well_pressure (float, optional): The pressure at the production well. Defaults to 0.\n",
    "        export_folder (str, optional): If given, path where to export the results. Defaults to\n",
    "            None.\n",
    "\n",
    "    Returns:\n",
    "        float: The maximum pressure at the injection wells.\n",
    "    \"\"\"\n",
    "    # TODO: adapt solve_fine with upscaled quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-belle",
   "metadata": {},
   "source": [
    "Perform the evaluation of the functional for the Spe10 benchmark of a given layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = 35\n",
    "folder_results = main_folder + \"results/\"\n",
    "\n",
    "# Read the SPE10 grid\n",
    "spe10 = Spe10(selected_layers)\n",
    "\n",
    "# Read the permeability associated to the given layer(s)\n",
    "perm_folder = spe10_folder + \"/perm/\"\n",
    "spe10.read_perm(perm_folder)\n",
    "# Define the function to evaluate that depends only on the position of the injection well\n",
    "CostFunctional = lambda x: solve_coarse(\n",
    "    sd_coarse, x, result, export_folder=folder_results\n",
    ")\n",
    "\n",
    "CostFunctionalFine = lambda x: solve_fine(\n",
    "    spe10, x, export_folder=folder_results\n",
    ")\n",
    "\n",
    "print(CostFunctional([231, 481]))\n",
    "print(CostFunctionalFine([231, 481]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38074229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Checkpoint1_solution(selected_layers, folder_results):\n",
    "    # Read the SPE10 grid\n",
    "    spe10 = Spe10(selected_layers)\n",
    "\n",
    "    # Read the permeability associated to the given layer(s)\n",
    "    perm_folder = spe10_folder + \"/perm/\"\n",
    "    spe10.read_perm(perm_folder)\n",
    "    perm_dict = spe10.perm_as_dict()\n",
    "\n",
    "    # Partition the grid\n",
    "    num_part = 20\n",
    "    part, sub_sds, sd_coarse = coarse_grid(spe10.sd, num_part)\n",
    "\n",
    "    # Define the upscaled permeability\n",
    "    kxx_up = np.zeros(spe10.sd.num_cells)\n",
    "    kxy_up = np.zeros(spe10.sd.num_cells)\n",
    "    kyx_up = np.zeros(spe10.sd.num_cells)\n",
    "    kyy_up = np.zeros(spe10.sd.num_cells)\n",
    "\n",
    "    kxx = np.zeros(spe10.sd.num_cells)\n",
    "\n",
    "    result = []\n",
    "    # Loop over the subdomains\n",
    "    for sub_sd_id, sub_sd in enumerate(sub_sds):\n",
    "        # Extract the permeability values associated to the current subdomain\n",
    "        mask = part == sub_sd_id\n",
    "        sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
    "        kxx[mask] = sub_perm[\"kxx\"]\n",
    "\n",
    "        # Upscale the permeability in the x-direction\n",
    "        folder = folder_results + str(sub_sd_id) + \"_x\"\n",
    "        q_h, grad_h = upscale(sub_sd, sub_perm, 0, folder)\n",
    "\n",
    "        # Upscale the permeability in the y-direction\n",
    "        folder = folder_results + str(sub_sd_id) + \"_y\"\n",
    "        q_v, grad_v = upscale(sub_sd, sub_perm, 1, folder)\n",
    "\n",
    "        # Compute the upscaling permeability tensor\n",
    "        kk = compute_tensor(grad_h, grad_v, q_h, q_v)\n",
    "\n",
    "        # Save the data\n",
    "        kxx_up[mask] = kk[0]\n",
    "        kxy_up[mask] = kk[1]\n",
    "        kyx_up[mask] = kk[2]\n",
    "        kyy_up[mask] = kk[3]\n",
    "\n",
    "        result.append([kk[0], kk[1], kk[2], kk[3]])\n",
    "\n",
    "        print(f\"Subdomain {sub_sd_id}: {kk}\")\n",
    "\n",
    "    return sd_coarse, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25631b9b",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fdd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def checkpoint2_solution(selected_layers, folder_results):\n",
    "\n",
    "     # Read the SPE10 grid\n",
    "    spe10 = Spe10(selected_layers)\n",
    "\n",
    "    # compute upscaling\n",
    "    sd_coarse, result = Checkpoint1_solution(selected_layers, folder_results)\n",
    "\n",
    "    # define cost functional on coarse scale (note that it depends on the upscaling)\n",
    "    CostFunctional = lambda x: solve_coarse(sd_coarse, x, result, export_folder=folder_results)\n",
    "\n",
    "    # define cost functional on fine scale \n",
    "    CostFunctionalFine = lambda x: solve_fine(spe10, x, export_folder=folder_results)\n",
    "\n",
    "    # stating point\n",
    "    mu_guess = [\n",
    "        (spe10.full_physdims[0]) / 2.0,\n",
    "        (spe10.full_physdims[1]) / 2.0,\n",
    "    ]\n",
    "\n",
    "    # TODO using both solve_corse and solve_fine\n",
    "    CostFunctional (mu_guess)\n",
    "    mu_est = mu_guess\n",
    "\n",
    "    return mu_est\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
