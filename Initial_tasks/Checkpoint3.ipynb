{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow and transport problem - SPE10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this checkpoint we investigate the transport problem where the advective field is computed with a Darcy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the grid we import NumPy, the SciPy sparse library and PorePy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import porepy as pp\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "cwd_folder = os.getcwd()\n",
    "spe10_folder = cwd_folder + \"/spe10/\"\n",
    "\n",
    "import sys; sys.path.insert(1, spe10_folder)\n",
    "\n",
    "from spe10 import Spe10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify number of cells in each dimension and the physical size of the domain. Then we create a Cartesian grid and compute geometric properties such as face centers, cell volumes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_layers = 35 \n",
    "\n",
    "# Define the class with the corresponding layer(s)\n",
    "spe10 = Spe10(selected_layers)\n",
    "# For simplicity we extract the grid form the class spe10\n",
    "sd = spe10.sd\n",
    "\n",
    "# Read the permeability associated to the given layer(s)\n",
    "perm_folder = spe10_folder + \"/perm/\"\n",
    "spe10.read_perm(perm_folder)\n",
    "perm_dict = spe10.perm_as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the data for the Darcy problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permeability\n",
    "perm = pp.SecondOrderTensor(kxx=perm_dict[\"kxx\"], kyy=perm_dict[\"kyy\"], kzz=perm_dict[\"kzz\"])      \n",
    "injection_rate = 1\n",
    "pos_well = [192.024, 233.17199999999997]  #this is the position found with the optimization\n",
    "#it will be kept fixed\n",
    "\n",
    "# Boundary conditions: homogeneous neumann everywhere\n",
    "b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
    "b_face_centers = sd.face_centers[:, b_faces]\n",
    "labels = np.array([\"neu\"] * b_faces.size)\n",
    "bc_val = np.zeros(sd.num_faces)\n",
    "bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
    "\n",
    "# Collect all parameters in a dictionary\n",
    "parameters = {\"second_order_tensor\": perm, \"bc\": bc, \"bc_values\": bc_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the data for the Darcy problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_key = \"flow\"\n",
    "flow_data = pp.initialize_default_data(sd, {}, flow_key, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now solve the Darcy problem by using the MPFA scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the lhr and rhs from the discretization of the diffusion operator\n",
    "mpfa = pp.Mpfa(flow_key)\n",
    "mpfa.discretize(sd, flow_data)\n",
    "A, b = mpfa.assemble_matrix_rhs(sd, flow_data)\n",
    "\n",
    "# Add the injection wells, all with the same injection rate\n",
    "b_wells = np.zeros_like(b)\n",
    "index_iwells = [\n",
    "   0,\n",
    "   spe10.full_shape[0] - 1,\n",
    "   spe10.full_shape[0] * spe10.full_shape[1] - spe10.full_shape[0],\n",
    "   spe10.full_shape[0] * spe10.full_shape[1] - 1,\n",
    "   ]\n",
    "b_wells[index_iwells] = injection_rate\n",
    "\n",
    "# Add the production well by using a Lagrange multiplier, first we identify the cell\n",
    "ij_well = np.floor( (np.asarray(pos_well) / spe10.spacing[:-1])).astype(int)\n",
    "index_pwell = spe10.full_shape[0] * ij_well[1] + ij_well[0]\n",
    "vect = np.zeros((sd.num_cells, 1))\n",
    "vect[index_pwell] = 1\n",
    "\n",
    "# Solve the linear system and compute the pressure by adding the constraint\n",
    "A = sps.bmat([[A, vect], [vect.T, None]], format=\"csc\")\n",
    "b = np.append(b + b_wells, 0)\n",
    "cell_p = sps.linalg.spsolve(A, b)[:-1]\n",
    "    \n",
    "# now data contains the discretization matrices build from MPFA\n",
    "mat_discr = flow_data[pp.DISCRETIZATION_MATRICES][flow_key]\n",
    "\n",
    "q = mat_discr[\"flux\"] @ cell_p + mat_discr[\"bound_flux\"] @ bc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we export the corresponding solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to export the flux                                                                                                   \n",
    "mvem = pp.MVEM(flow_key)                                                                                      \n",
    "mvem.discretize(sd, flow_data)                                                                                      \n",
    "                                                                                                                       \n",
    "# construct the P0 flux reconstruction                                                                                 \n",
    "cell_q = mvem.project_flux(sd, q, flow_data)\n",
    "\n",
    "save = pp.Exporter(sd, \"sol_p\", folder_name=\"transport\")\n",
    "\n",
    "data_to_export = [(\"kxx\", np.log10(perm_dict[\"kxx\"])), \n",
    "                  (\"kyy\", np.log10(perm_dict[\"kyy\"])), \n",
    "                  (\"kzz\", np.log10(perm_dict[\"kzz\"])),\n",
    "                  (\"cell_p\", cell_p),\n",
    "                  (\"cell_q\", cell_q)]\n",
    "save.write_vtu(data_to_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider the transport problem where now the advective field is the one computed from the Darcy problem. First we set the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport problem\n",
    "transport_key = \"transport\"\n",
    "delta_t = 500\n",
    "num_steps = 200\n",
    "\n",
    "# boundary conditions for the advection problem: no flow everywhere\n",
    "labels = np.array([\"neu\"] * b_faces.size)\n",
    "bc_val = np.zeros(sd.num_faces)\n",
    "bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
    "\n",
    "parameters = {\"darcy_flux\": q, \"bc\": bc, \"bc_values\": bc_val}\n",
    "transport_data = pp.initialize_default_data(sd, {}, transport_key, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the other cases, we now construct the upwind matrix and the mass matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the upwind and mass matrices\n",
    "upwind = pp.Upwind(transport_key)  #the problem is linear, upwind flux is fine (a bit diffusive)\n",
    "\n",
    "# discretize and get the matrices\n",
    "upwind.discretize(sd, transport_data)\n",
    "\n",
    "U, b_upwind = upwind.assemble_matrix_rhs(sd, transport_data)\n",
    "\n",
    "M = sps.csr_matrix(np.diag(sd.cell_volumes), shape=np.shape(U))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by using the implicit Euler we compute the concentration that is transported in the porous medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial condition: we have zero concentration except for a small square. The position of this square\n",
    "# is what we aim to find to match the curve measured at the well\n",
    "\n",
    "initial_conc_pos = [48,600]  # [292,505] #[300,400]\n",
    "L = 50\n",
    "\n",
    "ini_cond = np.logical_and((np.abs(sd.cell_centers[0,:]-initial_conc_pos[0])<L/2),(np.abs(sd.cell_centers[1,:]-initial_conc_pos[1])<L/2))\n",
    "c = np.zeros(sd.num_cells)\n",
    "c[ini_cond] = 1\n",
    "\n",
    "initial_mass = np.sum(c*sd.cell_volumes) #total mass. This is the max we can collect at the well over time\n",
    "\n",
    "#export initial condition\n",
    "save = pp.Exporter(sd, \"sol_c\", folder_name=\"transport\")\n",
    "save.write_vtu([(\"conc\", c)], time_step=0)\n",
    "\n",
    "# IE with LU factorization\n",
    "S = M + delta_t * U\n",
    "\n",
    "# this partis a bit tricky: at the production well I chose to enforce zero concentration or, if you want, \n",
    "# infinite storage volume. This is because flow and concentration flux should be able to exit the cell to mimic \n",
    "# a production well.\n",
    "\n",
    "# like for pressure, this is done with a Lagrange multiplier, adding a row and a column\n",
    "S = sps.bmat([[S, vect], [vect.T, None]], format=\"csc\")\n",
    "\n",
    "outflow = [] #this is to store the flow exiting from the well in time\n",
    "#the matrix will not change so it is convenient to factorize it once and for all\n",
    "lu = sps.linalg.splu(S.tocsc())\n",
    "\n",
    "for i in np.arange(num_steps):\n",
    "    b = M @ c + delta_t * b_upwind\n",
    "    b=np.append(b,0)\n",
    "    sol = lu.solve(b)\n",
    "    c = sol[:-1]\n",
    "    ll = sol[-1] #this is the Lagrange multiplier and represents the flux exiting from the \"well\"\n",
    "    save.write_vtu([(\"conc\", c)], time_step=(i+1)*delta_t)\n",
    "    outflow.append(ll)\n",
    "    \n",
    "plt.plot(np.arange(num_steps),outflow)\n",
    "# export the main pvd file\n",
    "time = np.arange((num_steps+1))*delta_t\n",
    "save.write_pvd(time)\n",
    "\n",
    "# let's check: mass conservation\n",
    "\n",
    "total_outflow = np.sum(outflow)\n",
    "final_internal_mass = np.sum(c*sd.cell_volumes)\n",
    "\n",
    "print('initial mass', initial_mass)\n",
    "print('total outflow', total_outflow)\n",
    "print('mass trapped in the domain', final_internal_mass)\n",
    "\n",
    "print('error in mass conservation',initial_mass-total_outflow-final_internal_mass) #must be 0 or machine eps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Checkpoint3_solution(selected_layers,initial_conc_pos, L=50):\n",
    "\n",
    "    outflow = np.zeros((200,))\n",
    "                       \n",
    "    # surrogate model implementation\n",
    "\n",
    "    return outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = [51, 71, 42, 20, 12, 2, 82]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    for i in range(7):\n",
    "    \n",
    "        outflow = Checkpoint3_solution(selected_layers[i], [120, 250] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
